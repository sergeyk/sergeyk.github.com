---
title: Home
layout: default
---

My goal is to deploy AI systems to improve human life.

<ul class="bullets">
    <li>Co-founder of <a href="https://volition.co">Volition</a>, a product studio.</li>
    <li>Co-founder of <a href="https://fullstackdeeplearning.com">Full Stack Deep Learning</a> (online, <a href="https://bit.ly/berkeleyfsdl">UC Berkeley</a>, and <a href="https://bit.ly/uwfsdl">University of Washington</a>)</li>
    <li>Co-founder of <a href="https://gradescope.com">Gradescope</a> (acquired by <a href="https://turnitin.com">Turnitin</a>)</li>
    <li>PhD in Computer Vision at <a href="https://eecs.berkeley.edu">UC Berkeley</a></li>
    <li>Advisor to <a href="https://gsv.ventures">GSV Ventures</a> and to personal portfolio startups</li>
</ul>

Feel free to get in touch via [Twitter](https://twitter.com/sergeykarayev) or [email](mailto:sergeykarayev@gmail.com).
I also have [LinkedIn](https://linkedin.in/in/sergeykarayev/) / [Github](https://github.com/sergeyk/) / a [CV](/resume/sergey_karayev_cv.pdf).

---

<h2>Full Stack Deep Learning</h2>
<p>
I co-founded an educational program that helps you go from a promising ML experiment to a shipped product, with real-world impact.
All of our materials are available for free online.
</p>
<ul class="projects">
    <li>
        <div>
            <div class="publication">
                <img class="post--image" src="https://fullstackdeeplearning.com/images/fsdl-2023-overview.png">
                <div>
                    <p>
                        <strong>2023 LLM Bootcamp</strong>
                        <br>
                        Learn best practices and tools for building LLM-powered apps!
                        <br>
                        <a href="https://charlesfrye.github.io/about/">Charles Frye</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://twitter.com/josh_tobin_">Josh Tobin</a>
                        <br>
                        [<a href="https://fullstackdeeplearning.com/llm-bootcamp">Register</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="https://fullstackdeeplearning.com/images/positioning.png">
                <div>
                    <p>
                        <strong>2022 Online Course</strong>
                        <br>
                        All lectures updated for 2022, with my lecture on <a href="https://fullstackdeeplearning.com/course/2022/lecture-7-foundation-models/">Foundation Models</a> particularly new.
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://twitter.com/josh_tobin_">Josh Tobin</a>,
                        <a href="https://charlesfrye.github.io/about/">Charles Frye</a>
                        <br>
                        [<a href="https://fullstackdeeplearning.com/course/2022/">Online Materials</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/fsdl_lab_intro.jpg">
                <div>
                    <p>
                        <strong>2021 Lab Project</strong>
                        <br>
                        In the 10-part lab, we build and deploy an end-to-end system to parse handwritten paragraphs.
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>
                        <br>
                        [<a href="https://fullstackdeeplearning.com/spring2021/lab-1/">Videos</a>]
                        [<a href="https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs#readme">Code</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/fsdl_group.jpg">
                <div>
                    <p>
                        <strong>2018-2021 Bootcamps and Courses</strong>
                        <br>
                        We hosted three weekend bootcamps in Berkeley, then taught the course as a UW Professional Master's Program course, a UC Brekeley undergrad course, and an online course open to all.
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://twitter.com/josh_tobin_">Josh Tobin</a>,
                        <a href="https://charlesfrye.github.io/about/">Charles Frye</a>,
                        <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>
                        <br>
                        [<a href="https://fall2019.fullstackdeeplearning.com">Fall 2019 Bootcamp</a>]
                        [<a href="https://bit.ly/uwfsdl">UW 2020 Course</a>]
                        [<a href="https://bit.ly/berkeleyfsdl">UC Berkeley 2021 Course</a>]
                        [<a href="https://fullstackdeeplearning.com/spring2021">Online 2021 Materials</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
</ul>

---

<h2>Misc Talks</h2>
<ul class="projects">
    <li>
        <div>
            <div class="publication">
                <img class="post--image" src="/images/talks/gpt3.png">
                <div>
                    <p>
                        <strong>GPT-3: what it is, and how it could affect education (January 2021)</strong>
                        <br>
                        Presented at <a href="https://gsv.ventures">GSV Ventures</a> Breakfast Club, aimed at a technical but not ML-savvy audience of ed tech founders and investors.
                        <br>
                        [<a href="/files/talks/gsv-gpt3-breakfast-club-jan-2021.pdf">slides</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/talks/grading_rubric_for_ai_applications.png">
                <div>
                    <p>
                        <strong>Grading Rubric for AI Applications (2019)</strong>
                        <br>
                        How to think about potential AI applications today, as a founder, investor, or buyer.
                        A 40-min talk given during the W&B Deep Learning for the Applied Deep Learning Fellowship.
                        <br>
                        [<a href="https://www.youtube.com/watch?v=SO5IrU2Ff4Y">video</a>]
                        [<a href="/files/talks/ai_for_good_2019_for_ml_class.pdf">slides</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/talks/ai_masterclass.png">
                <div>
                    <p>
                        <strong>AI Masterclass at ASU GSV Summit (2019)</strong>
                        <br>
                        A 40-min talk aimed at a general audience explaining the brief history of AI research, what's possible to do today, and how to think about developing AI products.
                        <br>
                        [<a href="https://www.youtube.com/watch?v=OUoxo09OOC0">video</a>]
                        [<a href="/files/talks/asu_gsv_ai_masterclass_2019.pdf">slides</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
</ul>

---

<h2>Gradescope</h2>
<p>
    I co-founded <a href="https://gradescope.com">Gradescope</a>, an AI-assisted tool for grading all kinds of exams and assignments.
    Gradescope was acquired as a standalone product by <a href="https://turnitin.com">Turnitin</a>, a leading ed tech provider, where I worked as Head of AI.
</p>
<ul class="projects">
    <li>
        <div>
            <div class="publication">
                <img class="post--image" src="/images/gradescope_hwr_2021.png">
                <div>
                    <p><strong>Full Page Handwriting Recognition via Image to Sequence Extraction</strong>
                        <br>
                        <a href="https://www.linkedin.com/in/sumeetssingh">Sumeet Singh</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>
                        <br>
                        ICDAR 2021
                        <br>
                        [<a href="https://arxiv.org/abs/2103.06450">paper</a>]
                        [<a
                            href="https://jack-clark.net/2021/04/12/import-ai-244-nvidia-makes-better-fake-images-deepmind-gets-better-at-weather-forecasting-plus-5000-hours-of-speech-data/">Import
                            AI newsletter</a>]
                        [<a href="https://read.deeplearning.ai/the-batch/issue-96/">The Batch newsletter</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/gradescope_ai_blog_post.png">
                <div>
                    <p>
                        <strong>Design Principles of AI-Assisted Grading</strong>
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://twitter.com/kevgski">Kevin Gutowski</a>
                        <br>
                        Turnitin Tech Blog 2020
                        <br>
                        [<a href="https://www.turnitin.com/blog/design-principles-of-ai-assisted-grading">blog post</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/gradescope_las_2020.png">
                <div>
                    <p><strong>Analysis of Grading Times of Short Answer Questions</strong>
                        <br>
                        <a href="https://www.linkedin.com/in/michael-yen/">Michael Yen</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://www.linkedin.com/in/ericxwangai/">Eric Wang</a>
                        <br>
                        Learning at Scale 2020
                        <br>
                        [<a href="/files/gradescope_las_2020.pdf">paper</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/grades_are_not_normal.png">
                <div>
                    <p><strong>Grades are not Normal: Improving Exam Score Models Using the Logit-Normal
                            Distribution</strong>
                        <br>
                        <a href="https://scholar.google.com/citations?user=ai8A090AAAAJ">Noah Arthurs</a>,
                        <a href="https://www.benstenhaug.com">Ben Stenhaug</a>,
                        <a href="https://stanford.edu/~cpiech/bio/index.html">Chris Piech</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>
                        <br>
                        Educational Data Mining 2019
                        <br>
                        [<a href="/files/grades_are_not_normal_2019.pdf">paper</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/gradescope_las_2018.png">
                <div>
                    <p><strong>How Do Professors Format Exams? An Analysis of Question Variety at Scale</strong>
                        <br>
                        <a href="https://people.ischool.berkeley.edu/~paul/">Paul Laskowski</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://people.ischool.berkeley.edu/~hearst/">Marti Hearst</a>
                        <br>
                        Learning at Scale 2018
                        <br>
                        [<a href="/files/gradescope_las_2018.pdf">paper</a>]
                        [<a href="/files/gradescope_las_2018_slides.pdf">slides</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/gradescope_team.jpg">
                <div>
                    <p><strong>The Future of Grading</strong>
                        <br>
                        The Gradescope Team
                        <br>
                        [<a href="https://blog.gradescope.com/the-future-of-grading-bc62920c3ae4">blog post</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/grading_ui.png">
                <div>
                    <p><strong>Gradescope: a Fast, Flexible, and Fair System for Scalable Assessment of Handwritten
                            Work</strong>
                        <br>
                        <a href="https://www.linkedin.com/in/arjun-singh-629216105">Arjun Singh</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://kevingutowski.com/">Kevin Gutowski</a>,
                        <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>
                        <br>
                        Learning at Scale 2017
                        <br>
                        [<a href="/files/gradescope_las_2017.pdf">paper</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
</ul>

---

<h2>PhD at UC Berkeley</h2>
<p>
    I finished a PhD in Computer Science at UC Berkeley, working on computer vision with <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>, teaching with <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>, and interning at Adobe Creative Technologies Lab and Artsy.
</p>
<ul class="projects">
    <li>
        <div>
            <h3>
                <span>Recognizing Image Style </span>
            </h3>
            <p>
                During a summer research internship at Adobe Creative Technologies Lab, I gathered datasets of photo and painting style, and used CNNs to classify different
                visual styles.
            </p>
            <div class="publication">
                <img class="post--image" src="/images/image_style_thumb.png">
                <div>
                    <p><strong>Recognizing Image Style</strong>
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://matttrent.com/">Matthew Trentacoste</a>,
                        <a href="https://www.linkedin.com/in/helen-han-28b79357">Helen Han</a>,
                        <a href="https://www.agarwala.org/">Aseem Agarwala</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>,
                        <a href="https://www.dgp.toronto.edu/~hertzman/">Aaron Hertzmann</a>,
                        <a href="https://www.adobe.com/technology/people/seattle/holger-winnemoeller.html">Holger
                            Winnemoeller</a>
                        <br>
                        BMVC 2014
                        <br>
                        [<a href="https://arxiv.org/abs/1311.3715">arXiv page</a>]
                        [<a href="/files/1311.3715v3.pdf">pdf</a>]
                        [<a href="https://github.com/sergeyk/recognizing_image_style_writeup">writeup sources</a>]
                        [<a href="https://vislab.berkeleyvision.org">code and data</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
    <li>
        <div>
            <h3>
                <span>Caffe Deep Learning Framework</span>
            </h3>
            <p>
                The deep learning paradigm shift was enabled by open source software, including Caffe from our Berkeley research lab.
                The Caffe team was <a href="https://eecs.berkeley.edu/news/2017/10/caffe-team-wins-everingham-prize-iccv-2017">honored by the Everingham Prize</a> in 2017.
            </p>
            <div class="publication">
                <img class="post--image" src="/images/caffeine.png">
                <div>
                    <p><strong>Caffe: Convolutional architecture for fast feature embedding</strong>
                        <br>
                        <a href="https://daggerfs.com/">Yangqing Jia</a>,
                        <a href="https://github.com/shelhamer">Evan Shelhamer</a>,
                        <a href="https://jeffdonahue.com/">Jeff Donahue</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://people.eecs.berkeley.edu/~jonlong/">Jonathan Long</a>,
                        <a href="https://www.rossgirshick.info/">Ross Girschick</a>,
                        <a href="https://www.linkedin.com/in/sergio-guadarrama-1724379/">Sergio Guadarrama</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        ACM Multimedia 2014
                        <br>
                        [<a href="https://arxiv.org/pdf/1408.5093.pdf">pdf</a>]
                        [<a href="https://caffe.berkeleyvision.org">project</a>]
                        [<a href="https://github.com/BVLC/caffe">code</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
    <li>
        <img class="post--image" src="/images/rayleigh_thumb.png">
        <div>
            <h3>
                <span><a href="/rayleigh-multicolor-search">Multi-color
                        image search</a></span>
            </h3>
            <p>
                During my summer internship at <a href="https://artsy.net">Artsy</a>, I became interested in color perception and indexing images by color.
                I developed an open-source system for quickly searching large image collections by multiple colors given as a palette, or by color similarity to a query image.</p>
        </div>
    </li>
    <li>
        <div>
            <h3>
                <span>Anytime Visual Recognition </span>
            </h3>
            <p>Features have different costs and different classes benefit from different features.
                A multi-class recognition system should dynamically select them to maximize performance under a cost
                budget.
                This line of work constitutes my <a
                    href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2014/EECS-2014-207.pdf">PhD Thesis</a>.
                Sources for all of the writeups below are <a
                    href="https://github.com/sergeyk/thesis_writeups">open-source</a>.</p>
            <div class="publication">
                <img class="post--image" src="/images/imagenet_thumb.png">
                <div>
                    <p><strong>Anytime Recognition of Objects and Scenes</strong>
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        CVPR 2014 (Oral)
                        <br>
                        [<a href="/files/cvpr_2014_anytime_recognition.pdf">pdf</a>]
                        [<a href="/files/cvpr_2014_slides.pdf">slides</a>]
                        [<a href="/files/cvpr_2014_poster.pdf">poster</a>]
                        [<a href="https://github.com/sergeyk/anytime_recognition">code</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/mdp_masks.png">
                <div>
                    <p><strong>Dynamic Feature Selection for Classification on a Budget</strong>
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        ICML-W 2013 - Prediction with Sequential Models
                        <br>
                        [<a href="/files/icmlw_2013_dynamic_feature_selection.pdf">pdf</a>]
                        [<a href="/files/icmlw_2013_slides.pdf">slides</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/timely_thumb.png">
                <div>
                    <p><strong>Timely Object Recognition</strong>
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://www.linkedin.com/in/tobias-baumgartner-b258a42/">Tobias Baumgartner</a>,
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        NIPS 2012
                        <br>
                        [<a href="/files/nips_2012_timely_object_recognition.pdf">pdf</a>]
                        [<a href="/files/nips_2012_timely_object_recognition_poster.pdf">poster</a>]
                        [<a href="https://github.com/sergeyk/timely_object_recognition">code</a>] (also need <a
                            href="https://github.com/sergeyk/skpyutils">sk-py-utils</a> and <a
                            href="https://github.com/sergeyk/skvisutils">sk-vis-utils</a>)
                    </p>
                </div>
            </div>
        </div>
    </li>
    <li>
        <div>
            <h3>
                <span>Depth-informed Object Detection </span>
            </h3>
            <p>Using the Microsoft Kinect, we gather a large dataset of indoor crowded scenes.
                We investigate ways to unify state-of-the-art object detection systems and improve them with depth
                information.</p>
            <div class="publication">
                <img class="post--image" src="/images/b3do_thumb_half.png">
                <div>
                    <p><strong>A Category-Level 3-D Object Dataset: Putting the Kinect to Work</strong>
                        <br>
                        <a href="https://alliejanoch.com/">Allison Janoch</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://daggerfs.com/">Yangqing Jia</a>,
                        <a href="https://www.cs.berkeley.edu/~barron/">Jonathan T. Barron</a>,
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://www.bu.edu/cs/profiles/kate-saenko/">Kate Saenko</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        ICCV-W 2011
                        <br>
                        [<a href="/files/iccvw2011.pdf">pdf</a>]
                        [<a href="https://kinectdata.com">dataset</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/iros2011_thumb.png">
                <div>
                    <p><strong>Practical 3-D Object Detection Using Category and Instance-level Appearance
                            Models</strong>
                        <br>
                        <a href="https://www.bu.edu/cs/profiles/kate-saenko/">Kate Saenko</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://daggerfs.com/">Yangqing Jia</a>,
                        <a href="https://www.linkedin.com/in/alex-shyr-3669623/">Alex Shyr</a>,
                        <a href="https://alliejanoch.com/">Allison Janoch</a>,
                        <a href="https://people.eecs.berkeley.edu/~jonlong/">Jonathan Long</a>,
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        IROS 2011
                        <br>
                        [<a href="/files/iros2011.pdf">pdf</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
    <li>
        <div>
            <h3>
                <span>Probabilistic Local Image Features</span>
            </h3>
            <p>Our method for additively decomposing local image patches shows best performance on a novel transparent
                object recognition dataset.
                We extend the model to multiple layers and apply it to general object classification.</p>
            <div class="publication">
                <img class="post--image" src="/images/cvpr2011_thumb.png">
                <div>
                    <p><strong>A Probabilistic Model for Recursive Factorized Image Features</strong>
                        <br>
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://www.cs.toronto.edu/~fidler/">Sanja Fidler</a>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        CVPR 2011
                        <br>
                        [<a href="/files/cvpr2011.pdf">pdf</a>]
                        [<a href="/files/cvpr2011_supp.pdf">supplement</a>]
                        [<a href="/files/cvpr2011_poster.pdf">poster</a>]
                        [<a href="/files/cvpr2011_slides.pdf">slides</a>]
                    </p>
                </div>
            </div>
            <div class="publication">
                <img class="post--image" src="/images/nips2009_thumb.png">
                <div>
                    <p><strong>An Additive Latent Feature Model for Transparent Object Recognition</strong>
                        <br>
                        <a href="https://www.d2.mpi-inf.mpg.de/People/mfritz">Mario Fritz</a>,
                        <a href="https://ps.is.tue.mpg.de/person/black/">Michael Black</a>,
                        <a href="https://www.linkedin.com/in/garybradski/">Gary Bradski</a>,
                        <strong><a href="https://sergeykarayev.com">Sergey Karayev</a></strong>,
                        <a href="https://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a>
                        <br>
                        NIPS 2009
                        <br>
                        [<a href="/files/nips2009.pdf">pdf</a>]
                    </p>
                </div>
            </div>
        </div>
    </li>
    <li>
        <img class="post--image" src="/images/foveal_explorer.jpg">
        <div>
            <h3><a href="/foveal-explorer">Foveal Explorer</a></h3>
            <p>A JavaScript applet for exploring images “foveally,” by moving a high-resolution area around.
                Written to gather visual attention data on Amazon Mechanical Turk.</p>
        </div>
    </li>

    <li>
        <img class="post--image" src="/images/cabfriendly_thumb.png">
        <div>
            <h3>
                <span><a href="/cabfriendly">CabFriendly</a></span>
            </h3>
            <p>A cloud-based mobile web application to match up users who request similar trips and would like to share
                a cab. The application is hosted on EC2 and combines several open-source frameworks with social
                networking and location-awareness APIs.</p>
        </div>
    </li>
    <li>
        <img class="post--image" src="/images/vs265_thumb.png">
        <div>
            <h3>
                Self-organizing sparse codes: VS 265 course project [<a href="/files/vs265_final.pdf">pdf</a>]
            </h3>
            <p>
                The biological motivation for sparse coding also suggests that the learned receptive field elements
                should be organized spatially.
                We investigate ways of enforcing a topography over the learned codes in a locally self-organizing map
                approach.
            </p>
        </div>
    </li>
</ul>

---

<h2>BS at University of Washington</h2>
<p>
    I was fortunate to work first with <a href="https://homes.cs.washington.edu/~luisceze/">Luis Ceze</a> and then <a href="https://www.smseitz.com">Steve Seitz</a> on undergraduate research at UW Seattle.
    In 2019, I was honored by the <a href="https://www.engr.washington.edu/alumni/diamond/2019honorees#early">UW Engineering Early Career Award</a>.
</p>
<ul class="projects">
    <li>
        <img class="post--image" src="/images/virtualzoom_thumb.png">
        <div>
            <h3>
                <span>Virtual Zoom [<a href="https://www.vimeo.com/4892120">video</a>] [<a
                        href="/files/vz_thesis.pdf">pdf</a>]
                </span>
            </h3>
            <p>With our application, the user can zoom in on a distant landmark using other people’s photographs.
                This work builds on a 3D scene modeling back end that infers the viewpoint of each photograph in an
                unordered collection (Photo Tourism).</p>
        </div>
    </li>
</ul>

---

## Other stuff

<ul class="links">
<li class="nothumb">
<a href="https://soundcloud.com/dj-jbgd">Some electronic music</a> I made from time to time.
</li>

<li class="nothumb">
<a href="https://firstpersonstories.tumblr.com/">First Person Stories</a>: a collection of tiny stories.
</li>

<li class="nothumb">
<a href="/archive/best_coast_tour">Best Coast Tour</a>: the summer after my first year in grad school, a friend and I biked down from the Canadian border to San Francisco.
</li>

<li class="nothumb">
<a href="/archive/eurotrip_09">Eurotrip '09</a>: a partial account of a "backpacking" trip to Western Europe I did before starting grad school.
</li>

<li class="nothumb">
<a href="/iamthedivebomber.net"><i class="fa fa-plane"></i></a>: my old personal website.
</li>
</ul>

{% include peoples_urls.md %}
